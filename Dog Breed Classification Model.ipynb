{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford Dogs - A Classfication problem\n",
    "\n",
    "Classification is a fundamental task in machine learning, and the Stanford Dogs Dataset provides a valuable resource for training and evaluating classification models. The dataset consists of images of various dog breeds, each labeled with the corresponding breed.\n",
    "\n",
    "By leveraging this dataset, we can develop a classification model that can accurately identify the breed of a given dog image. This can have practical applications in areas such as pet identification, animal welfare, and breed-specific research.\n",
    "\n",
    "To build a classification model using the Stanford Dogs Dataset, we can employ various machine learning techniques, such as convolutional neural networks (CNNs). CNNs are particularly effective for image classification tasks, as they can automatically learn relevant features from the input images.\n",
    "\n",
    "By training a CNN on the Stanford Dogs Dataset, we can teach the model to recognize distinctive patterns and characteristics of different dog breeds. Once trained, the model can be used to classify new dog images, providing predictions about the breed with a certain level of confidence.\n",
    "\n",
    "Evaluation of the classification model can be done using metrics such as accuracy, precision, recall, and F1 score. These metrics help assess the model's performance and determine its effectiveness in correctly classifying dog breeds.\n",
    "\n",
    "Overall, the Stanford Dogs Dataset offers a valuable opportunity to explore and develop classification models for dog breed identification. By leveraging this dataset and employing appropriate machine learning techniques, we can contribute to the field of computer vision and enhance our understanding of dog breeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 - Preprocessing\n",
    "\n",
    "Since we are using the **Stanford Dogs** dataset, there aren't really must preprocessing other than loading the data provides to us. - (What he trying to say???? >.< )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n",
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "# * Parses the annotation XML file to extract the bounding box coordinates\n",
    "def parse_xml(annotation_path):\n",
    "    tree = ET.parse(annotation_path)\n",
    "    root = tree.getroot()\n",
    "    bndbox = root.find('.//bndbox')\n",
    "    xmin = int(bndbox.find('xmin').text)\n",
    "    ymin = int(bndbox.find('ymin').text)\n",
    "    xmax = int(bndbox.find('xmax').text)\n",
    "    ymax = int(bndbox.find('ymax').text)\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "# * Loads the image and crops it based on the bounding box coordinates\n",
    "def load_image_and_crop(path, annotation_path):\n",
    "    # Decode paths\n",
    "    path = path.numpy().decode('utf-8')\n",
    "    annotation_path = annotation_path.numpy().decode('utf-8')\n",
    "    \n",
    "    xmin, ymin, xmax, ymax = parse_xml(annotation_path)\n",
    "    \n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = image[ymin:ymax, xmin:xmax]\n",
    "    return image\n",
    "\n",
    "# * Preprocesses the image by resizing and normalizing it\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = (image / 255.0) - 0.5  # Normalize\n",
    "    return image\n",
    "\n",
    "# * Combines the above functions to load and preprocess the image\n",
    "def load_and_preprocess_image(path, annotation_path):\n",
    "    image = tf.py_function(func=load_image_and_crop, inp=[path, annotation_path], Tout=tf.uint8)\n",
    "    image.set_shape([None, None, 3])\n",
    "    image = preprocess_image(image)\n",
    "    return image\n",
    "\n",
    "# * Prepares the dataset by loading and preprocessing the images\n",
    "def prepare_dataset(image_dir, annotation_dir):\n",
    "    image_paths = []\n",
    "    annotation_paths = []\n",
    "    \n",
    "    # Adjust the code to account for subdirectories\n",
    "    for breed_dir in os.listdir(image_dir):\n",
    "        breed_image_dir = os.path.join(image_dir, breed_dir)\n",
    "        breed_annotation_dir = os.path.join(annotation_dir, breed_dir)\n",
    "        for image_file in os.listdir(breed_image_dir):\n",
    "            image_path = os.path.join(breed_image_dir, image_file)\n",
    "            annotation_path = os.path.join(breed_annotation_dir, image_file.split('.')[0] + '.xml')\n",
    "            image_paths.append(image_path)\n",
    "            annotation_paths.append(annotation_path)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, annotation_paths))\n",
    "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# - Test the functions\n",
    "image_dir = 'data/images'\n",
    "annotation_dir = 'data/annotation-xml'\n",
    "\n",
    "# * Initialize the dataset\n",
    "dataset = prepare_dataset(image_dir, annotation_dir)\n",
    "\n",
    "# * Print the shape of the first 5 images\n",
    "for image in dataset.take(5):\n",
    "    print(image.shape)  # This should now print [224, 224, 3]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
