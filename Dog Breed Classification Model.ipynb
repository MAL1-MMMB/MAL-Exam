{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford Dogs - A Classfication problem\n",
    "\n",
    "Classification is a fundamental task in machine learning, and the Stanford Dogs Dataset provides a valuable resource for training and evaluating classification models. The dataset consists of images of various dog breeds, each labeled with the corresponding breed.\n",
    "\n",
    "By leveraging this dataset, we can develop a classification model that can accurately identify the breed of a given dog image. This can have practical applications in areas such as pet identification, animal welfare, and breed-specific research.\n",
    "\n",
    "To build a classification model using the Stanford Dogs Dataset, we can employ various machine learning techniques, such as convolutional neural networks (CNNs). CNNs are particularly effective for image classification tasks, as they can automatically learn relevant features from the input images.\n",
    "\n",
    "By training a CNN on the Stanford Dogs Dataset, we can teach the model to recognize distinctive patterns and characteristics of different dog breeds. Once trained, the model can be used to classify new dog images, providing predictions about the breed with a certain level of confidence.\n",
    "\n",
    "Evaluation of the classification model can be done using metrics such as accuracy, precision, recall, and F1 score. These metrics help assess the model's performance and determine its effectiveness in correctly classifying dog breeds.\n",
    "\n",
    "Overall, the Stanford Dogs Dataset offers a valuable opportunity to explore and develop classification models for dog breed identification. By leveraging this dataset and employing appropriate machine learning techniques, we can contribute to the field of computer vision and enhance our understanding of dog breeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 - Preprocessing 笞呻ｸ十n",
    "\n",
    "The dataset is split into two parts - Images and Annotations. \n",
    "\n",
    "The **Images** are pictures of the 120 different dog breeds present in the dataset. \n",
    "The **Annotations** are `.xml`-files, which contains information about where the dog is located in the different pictures and what breed it is.\n",
    "\n",
    "So first of all we need to load all of these informations into Python, so they can be used to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "dataset_dir = '.\\\\data'\n",
    "images_dir = os.path.join(dataset_dir, 'images')\n",
    "annotation_dir = os.path.join(dataset_dir, 'annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:51: SyntaxWarning: invalid escape sequence '\\%'\n",
      "<>:51: SyntaxWarning: invalid escape sequence '\\%'\n",
      "C:\\Users\\madsh\\AppData\\Local\\Temp\\ipykernel_28296\\3353025944.py:51: SyntaxWarning: invalid escape sequence '\\%'\n",
      "  filename_to_find = 'n%s\\%s.jpg'  # Replace with the actual filename you're looking for\n"
     ]
    }
   ],
   "source": [
    "# FUNCTION - Parse the annotations from their XML files to extract the image filename and label\n",
    "def parse_annotations(annotation_dir):\n",
    "    annotations = []\n",
    "    for root_dir, _, files in os.walk(annotation_dir):\n",
    "        for xml_file in files:\n",
    "            if xml_file.endswith('.xml'):\n",
    "                xml_path = os.path.join(root_dir, xml_file)\n",
    "                tree = ET.parse(xml_path)\n",
    "                root = tree.getroot()\n",
    "                \n",
    "                # Extract the folder and filename\n",
    "                folder = root.find('folder').text.strip()\n",
    "\n",
    "                #? If the folder is not present, then use the folder of the XML file\n",
    "                if not folder or folder == '%s':\n",
    "                    folder = os.path.basename(root_dir)\n",
    "\n",
    "                #? Check if the folder name contains an 'n' at the start, if not, add it\n",
    "                if not folder.startswith('n'):\n",
    "                    folder = 'n' + folder\n",
    "\n",
    "                filename = root.find('filename').text.strip() + '.jpg'  # Add .jpg extension\n",
    "\n",
    "                #? If the filename is not present, then use the filename from the XML file\n",
    "                if not filename or filename == '%s.jpg':\n",
    "                    filename = xml_file.replace('.xml', '.jpg')\n",
    "\n",
    "                \n",
    "                # Construct the full image filename\n",
    "                image_filename = os.path.join(folder, filename)\n",
    "                \n",
    "                # Extract the label\n",
    "                label = root.find('object').find('name').text.strip()\n",
    "                \n",
    "                # Append the annotation to the list\n",
    "                annotations.append((image_filename, label))\n",
    "    return annotations\n",
    "\n",
    "annotations = parse_annotations(annotation_dir)\n",
    "\n",
    "# * Convert annotations to DataFrame\n",
    "annotations_df = pd.DataFrame(annotations, columns=['filename', 'label'])\n",
    "\n",
    "# * Show the first 10 rows of the Annotation DataFrame\n",
    "print(\"\\nShow paths to the first 5 images\")\n",
    "for i in range(5):\n",
    "    print(annotations_df['filename'].iloc[i])\n",
    "\n",
    "\n",
    "# Find the row with the specified filename\n",
    "filename_to_find = 'n%s\\%s.jpg'  # Replace with the actual filename you're looking for\n",
    "matching_row = annotations_df[annotations_df['filename'] == filename_to_find]\n",
    "\n",
    "# Display the matching row\n",
    "if not matching_row.empty:\n",
    "    display(matching_row)\n",
    "else:\n",
    "    print(f\"No match found for filename: {filename_to_find}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Show the first 5 items in the dictionary\n",
      "n02085620\\n02085620_10074.jpg: Chihuahua\n",
      "n02085620\\n02085620_10131.jpg: Chihuahua\n",
      "n02085620\\n02085620_10621.jpg: Chihuahua\n",
      "n02085620\\n02085620_1073.jpg: Chihuahua\n",
      "n02085620\\n02085620_10976.jpg: Chihuahua\n",
      "\n",
      "Show paths to the first 5 images\n",
      ".\\data\\images\\n02085620\\n02085620_10074.jpg\n",
      ".\\data\\images\\n02085620\\n02085620_10131.jpg\n",
      ".\\data\\images\\n02085620\\n02085620_10621.jpg\n",
      ".\\data\\images\\n02085620\\n02085620_1073.jpg\n",
      ".\\data\\images\\n02085620\\n02085620_10976.jpg\n",
      "Loaded 20580 images\n",
      "Loaded 20580 labels\n"
     ]
    }
   ],
   "source": [
    "# * Load an image using the Keras load_img function\n",
    "def load_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    return img_to_array(img) / 255.0\n",
    "\n",
    "# Create a dictionary to map filenames to labels\n",
    "filename_to_label = dict(zip(annotations_df['filename'], annotations_df['label']))\n",
    "\n",
    "# Show the first 5 items in the dictionary\n",
    "print(\"\\nShow the first 5 items in the dictionary\")\n",
    "for i, (filename, label) in enumerate(filename_to_label.items()):\n",
    "    print(f\"{filename}: {label}\")\n",
    "    if i == 4:\n",
    "        break\n",
    "\n",
    "# List all image in the image directory\n",
    "\n",
    "\n",
    "image_paths = [os.path.join(images_dir, f) for f in filename_to_label.keys()]\n",
    "\n",
    "# ? Check if the image paths are correct\n",
    "print(\"\\nShow paths to the first 5 images\")\n",
    "for i in range(5):\n",
    "    print(image_paths[i])\n",
    "\n",
    "# Check if any image paths contain 'n%\\%s.jpg'\n",
    "for path in image_paths:\n",
    "    if '.\\\\data\\\\images\\\\n%s\\\\%s.jpg' in path:\n",
    "        print(f\"Found in path: {path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Create lists of images and labels\n",
    "images = [load_image(img_path) for img_path in image_paths]\n",
    "print(f\"Loaded {len(images)} images\")\n",
    "labels = [filename_to_label[os.path.relpath(img_path, images_dir)] for img_path in image_paths]\n",
    "print(f\"Loaded {len(labels)} labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical format\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)\n",
    "\n",
    "# Split into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels_categorical, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 1s/step - accuracy: 0.0104 - loss: 4.8539 - val_accuracy: 0.0134 - val_loss: 4.7618\n",
      "Epoch 2/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m594s\u001b[0m 1s/step - accuracy: 0.0156 - loss: 4.7366 - val_accuracy: 0.0160 - val_loss: 4.7181\n",
      "Epoch 3/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m587s\u001b[0m 1s/step - accuracy: 0.0185 - loss: 4.6993 - val_accuracy: 0.0177 - val_loss: 4.7110\n",
      "Epoch 4/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 1s/step - accuracy: 0.0197 - loss: 4.6802 - val_accuracy: 0.0187 - val_loss: 4.7044\n",
      "Epoch 5/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 1s/step - accuracy: 0.0215 - loss: 4.6733 - val_accuracy: 0.0207 - val_loss: 4.6870\n",
      "Epoch 6/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m597s\u001b[0m 1s/step - accuracy: 0.0228 - loss: 4.6658 - val_accuracy: 0.0199 - val_loss: 4.6764\n",
      "Epoch 7/10\n",
      "\u001b[1m515/515\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 1s/step - accuracy: 0.0261 - loss: 4.6477 - val_accuracy: 0.0236 - val_loss: 4.6653\n",
      "Epoch 8/10\n",
      "\u001b[1m344/515\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[1m2:55\u001b[0m 1s/step - accuracy: 0.0233 - loss: 4.6282"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# Define the model (using ResNet50 as an example)\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(label_encoder.classes_), activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Fine-tune the model by unfreezing some layers\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f'Validation accuracy: {val_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 - Compiling the model 沐ｧ\n",
    "\n",
    "The next step in the process is to compile the model itself. But before that we have define what **Loss function**, **Optimizer** and **Metrics** we are going to be using on this model.\n",
    "\n",
    "For the **Loss function** We have a few different options:\n",
    "\n",
    "(*Name a few different loss functions that would make sense to use for this project.*)\n",
    "\n",
    "For the **Optizimers** we also have a few different options:\n",
    "- *Adam*, *SGD*, *RMSProp* etc.\n",
    "\n",
    "For the **Metrcis** we also have a few different options:\n",
    "- *Accuarcy*, *PRecision*, *Recall*, *F1 score* etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 - Train the model 洫\n",
    "\n",
    "The next step in the process is to train the now compiled model on our data. Here we also have a little exploratory work in figuring out:\n",
    "- What *batch size* should we use?\n",
    "- What *number of epochs* should we use?\n",
    "- Is the model *overfitting* or *underfitting*?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Futher plan!\n",
    "\n",
    "1. **Choose the model architecture suitable for our problem** 洟能n",
    "    - Convolutional Neural Network (CNN - Good with Image data)\n",
    "    - Recurrent Neural Network (RNN - Good with sequence data)\n",
    "    - Another type??\n",
    "\n",
    "2. **Compile our model** 沐ｧ\n",
    "    - What *Loss function* should we use? - Cross-entropy is used for classification?\n",
    "    - What *Optimizer* should we use? Adam, SGD, RMSProp etc.\n",
    "    - What *Metrics* should we use? Accuracy, precision, recall, f1 score etc.\n",
    "\n",
    "3. **Train the model** 笞呻ｸ十n",
    "    - What *batch size* should we use?\n",
    "    - What *number of epochs* should we use?\n",
    "    - Is the model *overfitting* or *underfitting*?\n",
    "\n",
    "4. **Evalute the model** 沒浬n",
    "    - Is the model performing as we would like? Based upon our selected metrics to be unbiased 沽噂n",
    "\n",
    "5. **Tune Hyperparameter (Optional) - To improve performance** 沒\n",
    "    - Use grid search or another thing similar to find the best hyperparameters\n",
    "    - Adjust model layers, units, learning rate etc.\n",
    "\n",
    "6. **Save the Model (Optional) - But would be smart** 洫\n",
    "    - This can be done, so we don't have to run all the code later to get the model up and running!\n",
    "\n",
    "7. **Use the Model!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
