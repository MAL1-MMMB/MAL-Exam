{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford Dogs üê∂ - A Classfication problem\n",
    "Our group decided to tackle a project that sparked everyone's interest: using the Stanford Dogs dataset to create an image classification model capable of accurately identifying dog breeds. We wanted to make it personal and engaging by trying to identify the breed of a friend's dog.\n",
    "\n",
    "<-- *INSERT PICTURE HERE!* -->\n",
    "\n",
    "From a business perspective, our goal is to develop an image classification model with high accuracy in identifying dog breeds. This has various practical applications, such as enhancing pet adoption platforms by providing precise breed information, aiding veterinary services with breed-specific medical advice, and enabling personalized pet care products tailored to different breeds.\n",
    "\n",
    "We formulated the problem as a supervised learning task, leveraging the labelled images in the Stanford Dogs dataset. Our aim is to train a model that learns to distinguish the characteristics of each breed and applies this knowledge to predict the breed of new, unseen images.\n",
    "\n",
    "To evaluate the performance of our model, we will use several metrics. ``Accuracy`` will be our primary metric, indicating the proportion of correctly identified breeds out of all predictions. We'll also assess ``precision``, ``recall``, and the ``F1-score`` to gain deeper insights into the performance for each breed, particularly if the dataset is imbalanced. Additionally, a confusion matrix will help visualize the model's performance and pinpoint misclassifications, enabling us to refine and enhance the model further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Get the data\n",
    "- Find and document where you can get the data from\n",
    "- Get the data\n",
    "- Check the size and type of data (time series, geographical etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00 Getting the data üóÉÔ∏è\n",
    "\n",
    "In terms for getting the actual data, we found the dataset itself on Kaggle, a platform for data scientists and machine learning enthusiasts. It hosts a vast array of datasets, including the [Stanford Dogs dataset](https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset/code), which is a widely used benchmark for image classification tasks. \n",
    "\n",
    "The dataset consits of over 20,000 images of dogs, encompassing 120 different breeds, making it an ideal resourcs for training and evaluation our model.\n",
    "\n",
    "**NOTE**: It requires an Kaggle account to download the dataset from their website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Exploring the Data\n",
    "- Create a copy of the data for explorations (sampling it down to a manageable size, if necessary)\n",
    "- Create a Jupyter notebook to keep a record of ytour data exploration\n",
    "- Study each feature and its characteristics:\n",
    "    - Name\n",
    "    - Type\n",
    "    - Percentage of missing values\n",
    "    - Check for outliers, rounding errors etc.\n",
    "- For supervised learning tasks, identify the target(s)\n",
    "- Visualize the data\n",
    "- Study the correlation between features\n",
    "- Identify the promising transformations you may want to apploy (e.g. convert skewed targets to normal via. a `log` transformation)\n",
    "- Document what you have learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 Exploring the dataset üîç\n",
    "\n",
    "Now that we have the dataset in our possion, we can take a closer look at it. The dataset itself consists more directly of **images** and **annotations**.\n",
    "\n",
    "The **images** are the actually images of the different breeds stored as `.jpg`-files.\n",
    "The **annotations** seems to be some kind of `.xml`-files, which contains information about where the dogs are located in the images and what breed the dog is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Look at the first image in the dataset and print out the dimensions of the image and the number of channels\n",
    "\n",
    "# TODO: Look at the first annotation in the dataset and print out the number of objects in the annotation\n",
    "\n",
    "# TODO: Make a histogram of the total number of images for each dog breed in the dataset. (This will help us determine if we need to look at F1 score instead of accuracy)\n",
    "\n",
    "# ANY OTHER IDEAS?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 Prepare the data\n",
    "Notes:\n",
    "- Work on copies of the data (keep the original dataset intact)\n",
    "- Write functions for all data transformation you apply, for three reasons:\n",
    "    - So you can easily prepare the data next time you run your code\n",
    "    - So you can apply these transformations in future projects\n",
    "    - To clean and prepare the test set.\n",
    "\n",
    "\n",
    "1. Data cleaning:\n",
    "    - Fix or remove outliers (or keep them)\n",
    "    - Fill in the missing values (e.g. with zero, mean, median, regression....) or drop their rows (or columns)\n",
    "2. Feature selection (optional):\n",
    "    - Drop the features that provide no useful information for the task (e.g. a customer ID is usually useless for modelling).\n",
    "3. Feature engineering, where appropriate:\n",
    "    - Discretize continuos features\n",
    "    - Use one-hot encoding if/when relevant\n",
    "    * Add promising transformations of features (e.g. $\\log(x)$, $\\sqrt{x}$, $x^2$, etc)\n",
    "    * Aggregate features into promising new features\n",
    "4. Feature scaling: standardise or normalise features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 Preparing the data for training üõ†Ô∏è\n",
    "\n",
    "<-- *Write something here* -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Include the script to rename all the folders? (I think this is a good idea)\n",
    "\n",
    "# TODO: ANY OTHER IDEAS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<-- *Explanation for the below approach* -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16508 images belonging to 120 classes.\n",
      "Found 4072 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "# Define paths\n",
    "images_dir = 'images'\n",
    "\n",
    "# Create the ImageDataGenerator data generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2, # 20% of the data will be used for validation\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    ")\n",
    "\n",
    "# Load all images to be used for the training set.\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    images_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Load all images to be used for the validation set.\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    images_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Compiling the model ‚öôÔ∏è\n",
    "\n",
    "The next step in the process is to compile the model itself. But before that we have define what **Loss function**, **Optimizer** and **Metrics** we are going to be using on this model.\n",
    "\n",
    "For the **Loss function** We have a few different options:\n",
    "\n",
    "(*Name a few different loss functions that would make sense to use for this project.*)\n",
    "\n",
    "For the **Optizimers** we also have a few different options:\n",
    "- *Adam*, *SGD*, *RMSProp* etc.\n",
    "\n",
    "For the **Metrcis** we also have a few different options:\n",
    "- *Accuarcy*, *PRecision*, *Recall*, *F1 score* etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# ? Load pre-trained model, if available\n",
    "if os.path.exists('model.h5'):\n",
    "    model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# ? Otherwise, we need to create a new instance of the model.\n",
    "else:\n",
    "    # Load the ResNet50 model, pre-trained on ImageNet\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Add custom layers on top of the base model\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Unfreeze the last few layers of the base model\n",
    "    for layer in base_model.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model üèãÔ∏è‚Äç‚ôÄÔ∏è\n",
    "\n",
    "The next step in the process is to train the now compiled model on our data. Here we also have a little exploratory work in figuring out:\n",
    "- What *batch size* should we use?\n",
    "- What *number of epochs* should we use?\n",
    "- Is the model *overfitting* or *underfitting*?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 39s 311ms/step - loss: 10.5811 - accuracy: 0.7078 - val_loss: 10.6033 - val_accuracy: 0.7212\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 30s 300ms/step - loss: 10.5031 - accuracy: 0.7328 - val_loss: 10.6035 - val_accuracy: 0.6862\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 10.5157 - accuracy: 0.7056 - val_loss: 10.5632 - val_accuracy: 0.6825\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 30s 300ms/step - loss: 10.4613 - accuracy: 0.7141 - val_loss: 10.3532 - val_accuracy: 0.7600\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 10.4053 - accuracy: 0.7184 - val_loss: 10.3828 - val_accuracy: 0.7255\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 31s 310ms/step - loss: 10.3486 - accuracy: 0.7275 - val_loss: 10.3705 - val_accuracy: 0.7150\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 10.3175 - accuracy: 0.7194 - val_loss: 10.3688 - val_accuracy: 0.6988\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 10.2617 - accuracy: 0.7241 - val_loss: 10.3230 - val_accuracy: 0.6888\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 30s 305ms/step - loss: 10.2531 - accuracy: 0.7100 - val_loss: 10.1622 - val_accuracy: 0.7450\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 10.1784 - accuracy: 0.7341 - val_loss: 10.1689 - val_accuracy: 0.7216\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 10.1247 - accuracy: 0.7350 - val_loss: 10.1463 - val_accuracy: 0.7262\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 10.0656 - accuracy: 0.7481 - val_loss: 10.1802 - val_accuracy: 0.7038\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 10.0691 - accuracy: 0.7387 - val_loss: 10.0528 - val_accuracy: 0.7525\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 30s 299ms/step - loss: 9.9988 - accuracy: 0.7344 - val_loss: 10.1200 - val_accuracy: 0.6950\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 9.9873 - accuracy: 0.7247 - val_loss: 10.0119 - val_accuracy: 0.7384\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 9.9542 - accuracy: 0.7284 - val_loss: 10.0272 - val_accuracy: 0.7188\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 9.8504 - accuracy: 0.7600 - val_loss: 10.0034 - val_accuracy: 0.7075\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 9.8367 - accuracy: 0.7553 - val_loss: 9.9367 - val_accuracy: 0.7212\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 30s 298ms/step - loss: 9.8058 - accuracy: 0.7409 - val_loss: 9.8313 - val_accuracy: 0.7139\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 30s 300ms/step - loss: 9.7654 - accuracy: 0.7478 - val_loss: 9.7973 - val_accuracy: 0.7275\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# - Function the limit the number of batches per epoch for faster iterations.\n",
    "def limit_batches(generator, max_batches):\n",
    "    while True:\n",
    "        for i, (x_batch, y_batch) in enumerate(generator):\n",
    "            if i >= max_batches:\n",
    "                break\n",
    "            yield (x_batch, y_batch)\n",
    "\n",
    "# * Current limits:\n",
    "max_train_batches = 100 # It's a good starting point, but needs to be adjusted for better results.\n",
    "max_validation_batches = 25 # It's a good starting point.\n",
    "\n",
    "# ? Callbacks and their usage\n",
    "\n",
    "# 1. Reduce learning rate when a metric has stopped improving.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001, verbose=1)\n",
    "# 2. Stop training when a monitored quantity has stopped improving.\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "# 3. Save the model after every epoch.\n",
    "model_checkpoint = ModelCheckpoint('model.h5', save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "# ! 1st round of training\n",
    "history = model.fit(\n",
    "    limit_batches(train_generator, max_train_batches),\n",
    "    validation_data=limit_batches(validation_generator, max_validation_batches),\n",
    "    epochs=20, # Use a small number of epochs to speed up the process (10 epochs = 5 mins on GPU - With validation accuracy of 0.18 after 10 epochs)\n",
    "    steps_per_epoch=max_train_batches,\n",
    "    validation_steps=max_validation_batches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 29s 229ms/step - loss: 9.8302 - accuracy: 0.7205\n",
      "Validation accuracy: 72.05%\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // validation_generator.batch_size)\n",
    "print(f'Validation accuracy: {val_accuracy * 100:.2f}%')\n",
    "\n",
    "# Save the model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 Short-list promising models\n",
    "We expect you to do some additional research and train at **least** one model per team member!\n",
    "\n",
    "1. Train mainly quick and dirty models from different categories (e.g. linear, SVM, Random Forests etc.) using default parameters\n",
    "2. Measure and compare their performance\n",
    "3. Analyse the most significant variables from each algorithm.\n",
    "4. Analyse the types of errors the models make\n",
    "5. Have a quick round of feature selection and engineering if necessary\n",
    "6. Have one or two more quick iterations of the five previous steps.\n",
    "7. Short-list the top three to five most promising models, prefeering models that make *different* types of errors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06 Fine-tune the system\n",
    "\n",
    "1. Fine-tune the hyperparameters\n",
    "2. Once you are confident about our final model, measure its performance on test set to estimate the generalisation error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07 Present your solution\n",
    "\n",
    "1. Document what you ahve done\n",
    "2. Create a *nice* 15 minute video presentation with slides\n",
    "    - Make sure you highlight the big picture first.\n",
    "3. Explain why your solutions achieves the business objective\n",
    "4. Don't forget to present interesting points you noticed along the way:\n",
    "    - Describe what worked and what did not.\n",
    "    - List your assumptions and your model's limitations.\n",
    "5. Ensure your key finds are communicated through nice visualisations or easy-to-remember statements (e.g. \"*The median income is the number-one predictor of housing prices*\")\n",
    "6. Upload the presentation to some online platform, e.g. Youtube, Vimeo, and supply a link to the video in the notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
